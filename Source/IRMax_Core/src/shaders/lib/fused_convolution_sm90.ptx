//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35813241
// Cuda compilation tools, release 12.9, V12.9.41
// Based on NVVM 7.0.1
//

.version 8.8
.target sm_90
.address_size 64

	// .globl	fused_mimo

.visible .entry fused_mimo(
	.param .u64 fused_mimo_param_0,
	.param .u64 fused_mimo_param_1,
	.param .u64 fused_mimo_param_2,
	.param .align 4 .b8 fused_mimo_param_3[20],
	.param .u64 fused_mimo_param_4,
	.param .u64 fused_mimo_param_5
)
{
	.reg .pred 	%p<13>;
	.reg .b16 	%rs<11>;
	.reg .f32 	%f<98>;
	.reg .b32 	%r<34>;
	.reg .b64 	%rd<105>;


	ld.param.u64 	%rd11, [fused_mimo_param_0];
	ld.param.u64 	%rd12, [fused_mimo_param_1];
	ld.param.u64 	%rd9, [fused_mimo_param_2];
	ld.param.u64 	%rd13, [fused_mimo_param_4];
	ld.param.u64 	%rd10, [fused_mimo_param_5];
	ld.param.u32 	%r19, [fused_mimo_param_3+12];
	ld.param.u32 	%r17, [fused_mimo_param_3+4];
	ld.param.u32 	%r16, [fused_mimo_param_3];
	cvta.to.global.u64 	%rd1, %rd12;
	cvta.to.global.u64 	%rd2, %rd11;
	cvta.to.global.u64 	%rd3, %rd13;
	mov.u32 	%r21, %ntid.x;
	mov.u32 	%r22, %ctaid.x;
	mov.u32 	%r23, %tid.x;
	mad.lo.s32 	%r1, %r22, %r21, %r23;
	setp.ge.u32 	%p1, %r1, %r19;
	@%p1 bra 	$L__BB0_25;

	mov.u32 	%r4, %ctaid.y;
	setp.ge.u32 	%p2, %r4, %r17;
	@%p2 bra 	$L__BB0_25;

	cvt.u64.u32 	%rd4, %r4;
	cvta.to.global.u64 	%rd14, %rd10;
	mul.wide.u32 	%rd15, %r4, 8;
	add.s64 	%rd16, %rd14, %rd15;
	ld.global.nc.u32 	%r5, [%rd16+4];
	ld.global.nc.u32 	%r32, [%rd16];
	add.s32 	%r7, %r5, %r32;
	setp.lt.u32 	%p3, %r32, %r7;
	@%p3 bra 	$L__BB0_4;
	bra.uni 	$L__BB0_3;

$L__BB0_4:
	cvt.u64.u32 	%rd5, %r16;
	mul.wide.u32 	%rd6, %r19, 2;
	shl.b32 	%r24, %r1, 1;
	cvt.u64.u32 	%rd7, %r24;
	cvt.u64.u32 	%rd8, %r17;
	and.b32  	%r31, %r5, 3;
	setp.eq.s32 	%p4, %r31, 0;
	mov.f32 	%f86, 0f00000000;
	mov.f32 	%f87, %f86;
	@%p4 bra 	$L__BB0_10;

	mov.f32 	%f86, 0f00000000;

$L__BB0_6:
	.pragma "nounroll";
	mul.wide.u32 	%rd17, %r32, 4;
	add.s64 	%rd18, %rd3, %rd17;
	ld.global.nc.u16 	%rs1, [%rd18];
	cvt.u64.u16 	%rd19, %rs1;
	mul.lo.s64 	%rd20, %rd19, %rd5;
	ld.global.nc.u16 	%rs2, [%rd18+2];
	cvt.u64.u16 	%rd21, %rs2;
	add.s64 	%rd22, %rd20, %rd21;
	mul.lo.s64 	%rd23, %rd6, %rd22;
	add.s64 	%rd24, %rd23, %rd7;
	shl.b64 	%rd25, %rd24, 2;
	add.s64 	%rd26, %rd2, %rd25;
	ld.global.nc.f32 	%f3, [%rd26+4];
	mul.lo.s64 	%rd27, %rd22, %rd8;
	add.s64 	%rd28, %rd27, %rd4;
	mul.lo.s64 	%rd29, %rd6, %rd28;
	add.s64 	%rd30, %rd29, %rd7;
	shl.b64 	%rd31, %rd30, 2;
	add.s64 	%rd32, %rd1, %rd31;
	ld.global.nc.f32 	%f4, [%rd32+4];
	ld.global.nc.f32 	%f5, [%rd32];
	ld.global.nc.f32 	%f6, [%rd26];
	fma.rn.f32 	%f87, %f6, %f5, %f87;
	setp.eq.s32 	%p5, %r1, 0;
	@%p5 bra 	$L__BB0_8;

	neg.f32 	%f68, %f3;
	fma.rn.f32 	%f87, %f68, %f4, %f87;
	fma.rn.f32 	%f69, %f6, %f4, %f86;
	fma.rn.f32 	%f86, %f3, %f5, %f69;
	bra.uni 	$L__BB0_9;

$L__BB0_8:
	fma.rn.f32 	%f86, %f3, %f4, %f86;

$L__BB0_9:
	add.s32 	%r32, %r32, 1;
	add.s32 	%r31, %r31, -1;
	setp.ne.s32 	%p6, %r31, 0;
	@%p6 bra 	$L__BB0_6;

$L__BB0_10:
	add.s32 	%r25, %r5, -1;
	setp.lt.u32 	%p7, %r25, 3;
	@%p7 bra 	$L__BB0_24;

$L__BB0_11:
	mul.wide.u32 	%rd33, %r32, 4;
	add.s64 	%rd34, %rd3, %rd33;
	ld.global.nc.u16 	%rs3, [%rd34];
	cvt.u64.u16 	%rd35, %rs3;
	mul.lo.s64 	%rd36, %rd35, %rd5;
	ld.global.nc.u16 	%rs4, [%rd34+2];
	cvt.u64.u16 	%rd37, %rs4;
	add.s64 	%rd38, %rd36, %rd37;
	mul.lo.s64 	%rd39, %rd6, %rd38;
	add.s64 	%rd40, %rd39, %rd7;
	shl.b64 	%rd41, %rd40, 2;
	add.s64 	%rd42, %rd2, %rd41;
	ld.global.nc.f32 	%f19, [%rd42+4];
	mul.lo.s64 	%rd43, %rd38, %rd8;
	add.s64 	%rd44, %rd43, %rd4;
	mul.lo.s64 	%rd45, %rd6, %rd44;
	add.s64 	%rd46, %rd45, %rd7;
	shl.b64 	%rd47, %rd46, 2;
	add.s64 	%rd48, %rd1, %rd47;
	ld.global.nc.f32 	%f20, [%rd48+4];
	ld.global.nc.f32 	%f21, [%rd48];
	ld.global.nc.f32 	%f22, [%rd42];
	fma.rn.f32 	%f88, %f22, %f21, %f87;
	setp.eq.s32 	%p8, %r1, 0;
	@%p8 bra 	$L__BB0_13;

	neg.f32 	%f70, %f19;
	fma.rn.f32 	%f88, %f70, %f20, %f88;
	fma.rn.f32 	%f71, %f22, %f20, %f86;
	fma.rn.f32 	%f89, %f19, %f21, %f71;
	bra.uni 	$L__BB0_14;

$L__BB0_13:
	fma.rn.f32 	%f89, %f19, %f20, %f86;

$L__BB0_14:
	add.s32 	%r26, %r32, 1;
	mul.wide.u32 	%rd49, %r26, 4;
	add.s64 	%rd50, %rd3, %rd49;
	ld.global.nc.u16 	%rs5, [%rd50];
	cvt.u64.u16 	%rd51, %rs5;
	mul.lo.s64 	%rd52, %rd51, %rd5;
	ld.global.nc.u16 	%rs6, [%rd50+2];
	cvt.u64.u16 	%rd53, %rs6;
	add.s64 	%rd54, %rd52, %rd53;
	mul.lo.s64 	%rd55, %rd6, %rd54;
	add.s64 	%rd56, %rd55, %rd7;
	shl.b64 	%rd57, %rd56, 2;
	add.s64 	%rd58, %rd2, %rd57;
	ld.global.nc.f32 	%f29, [%rd58+4];
	mul.lo.s64 	%rd59, %rd54, %rd8;
	add.s64 	%rd60, %rd59, %rd4;
	mul.lo.s64 	%rd61, %rd6, %rd60;
	add.s64 	%rd62, %rd61, %rd7;
	shl.b64 	%rd63, %rd62, 2;
	add.s64 	%rd64, %rd1, %rd63;
	ld.global.nc.f32 	%f30, [%rd64+4];
	ld.global.nc.f32 	%f31, [%rd64];
	ld.global.nc.f32 	%f32, [%rd58];
	fma.rn.f32 	%f90, %f32, %f31, %f88;
	@%p8 bra 	$L__BB0_16;

	neg.f32 	%f72, %f29;
	fma.rn.f32 	%f90, %f72, %f30, %f90;
	fma.rn.f32 	%f73, %f32, %f30, %f89;
	fma.rn.f32 	%f91, %f29, %f31, %f73;
	bra.uni 	$L__BB0_17;

$L__BB0_16:
	fma.rn.f32 	%f91, %f29, %f30, %f89;

$L__BB0_17:
	add.s32 	%r27, %r32, 2;
	mul.wide.u32 	%rd65, %r27, 4;
	add.s64 	%rd66, %rd3, %rd65;
	ld.global.nc.u16 	%rs7, [%rd66];
	cvt.u64.u16 	%rd67, %rs7;
	mul.lo.s64 	%rd68, %rd67, %rd5;
	ld.global.nc.u16 	%rs8, [%rd66+2];
	cvt.u64.u16 	%rd69, %rs8;
	add.s64 	%rd70, %rd68, %rd69;
	mul.lo.s64 	%rd71, %rd6, %rd70;
	add.s64 	%rd72, %rd71, %rd7;
	shl.b64 	%rd73, %rd72, 2;
	add.s64 	%rd74, %rd2, %rd73;
	ld.global.nc.f32 	%f39, [%rd74+4];
	mul.lo.s64 	%rd75, %rd70, %rd8;
	add.s64 	%rd76, %rd75, %rd4;
	mul.lo.s64 	%rd77, %rd6, %rd76;
	add.s64 	%rd78, %rd77, %rd7;
	shl.b64 	%rd79, %rd78, 2;
	add.s64 	%rd80, %rd1, %rd79;
	ld.global.nc.f32 	%f40, [%rd80+4];
	ld.global.nc.f32 	%f41, [%rd80];
	ld.global.nc.f32 	%f42, [%rd74];
	fma.rn.f32 	%f92, %f42, %f41, %f90;
	@%p8 bra 	$L__BB0_19;

	neg.f32 	%f74, %f39;
	fma.rn.f32 	%f92, %f74, %f40, %f92;
	fma.rn.f32 	%f75, %f42, %f40, %f91;
	fma.rn.f32 	%f93, %f39, %f41, %f75;
	bra.uni 	$L__BB0_20;

$L__BB0_19:
	fma.rn.f32 	%f93, %f39, %f40, %f91;

$L__BB0_20:
	add.s32 	%r28, %r32, 3;
	mul.wide.u32 	%rd81, %r28, 4;
	add.s64 	%rd82, %rd3, %rd81;
	ld.global.nc.u16 	%rs9, [%rd82];
	cvt.u64.u16 	%rd83, %rs9;
	mul.lo.s64 	%rd84, %rd83, %rd5;
	ld.global.nc.u16 	%rs10, [%rd82+2];
	cvt.u64.u16 	%rd85, %rs10;
	add.s64 	%rd86, %rd84, %rd85;
	mul.lo.s64 	%rd87, %rd6, %rd86;
	add.s64 	%rd88, %rd87, %rd7;
	shl.b64 	%rd89, %rd88, 2;
	add.s64 	%rd90, %rd2, %rd89;
	ld.global.nc.f32 	%f49, [%rd90+4];
	mul.lo.s64 	%rd91, %rd86, %rd8;
	add.s64 	%rd92, %rd91, %rd4;
	mul.lo.s64 	%rd93, %rd6, %rd92;
	add.s64 	%rd94, %rd93, %rd7;
	shl.b64 	%rd95, %rd94, 2;
	add.s64 	%rd96, %rd1, %rd95;
	ld.global.nc.f32 	%f50, [%rd96+4];
	ld.global.nc.f32 	%f51, [%rd96];
	ld.global.nc.f32 	%f52, [%rd90];
	fma.rn.f32 	%f87, %f52, %f51, %f92;
	@%p8 bra 	$L__BB0_22;

	neg.f32 	%f76, %f49;
	fma.rn.f32 	%f87, %f76, %f50, %f87;
	fma.rn.f32 	%f77, %f52, %f50, %f93;
	fma.rn.f32 	%f86, %f49, %f51, %f77;
	bra.uni 	$L__BB0_23;

$L__BB0_22:
	fma.rn.f32 	%f86, %f49, %f50, %f93;

$L__BB0_23:
	add.s32 	%r32, %r32, 4;
	setp.lt.u32 	%p12, %r32, %r7;
	@%p12 bra 	$L__BB0_11;
	bra.uni 	$L__BB0_24;

$L__BB0_3:
	mov.f32 	%f87, 0f00000000;
	mov.f32 	%f86, %f87;

$L__BB0_24:
	shl.b32 	%r29, %r1, 1;
	cvt.u64.u32 	%rd97, %r29;
	cvt.u64.u32 	%rd98, %r19;
	mul.lo.s64 	%rd99, %rd4, %rd98;
	shl.b64 	%rd100, %rd99, 1;
	add.s64 	%rd101, %rd100, %rd97;
	cvta.to.global.u64 	%rd102, %rd9;
	shl.b64 	%rd103, %rd101, 2;
	add.s64 	%rd104, %rd102, %rd103;
	st.global.f32 	[%rd104], %f87;
	st.global.f32 	[%rd104+4], %f86;

$L__BB0_25:
	ret;

}

