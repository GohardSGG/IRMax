//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-35813241
// Cuda compilation tools, release 12.9, V12.9.41
// Based on NVVM 20.0.0
//

.version 8.8
.target sm_120
.address_size 64

	// .globl	fused_mimo

.visible .entry fused_mimo(
	.param .u64 .ptr .align 1 fused_mimo_param_0,
	.param .u64 .ptr .align 1 fused_mimo_param_1,
	.param .u64 .ptr .align 1 fused_mimo_param_2,
	.param .align 4 .b8 fused_mimo_param_3[20],
	.param .u64 .ptr .align 1 fused_mimo_param_4,
	.param .u64 .ptr .align 1 fused_mimo_param_5
)
{
	.reg .pred 	%p<17>;
	.reg .b16 	%rs<15>;
	.reg .b32 	%r<30>;
	.reg .f32 	%f<131>;
	.reg .b64 	%rd<134>;

	ld.param.u32 	%r1, [fused_mimo_param_3];
	ld.param.u32 	%r2, [fused_mimo_param_3+4];
	ld.param.u32 	%r3, [fused_mimo_param_3+12];
	ld.param.u64 	%rd15, [fused_mimo_param_0];
	ld.param.u64 	%rd16, [fused_mimo_param_1];
	ld.param.u64 	%rd17, [fused_mimo_param_4];
	ld.param.u64 	%rd14, [fused_mimo_param_5];
	cvta.to.global.u64 	%rd1, %rd16;
	cvta.to.global.u64 	%rd2, %rd15;
	cvta.to.global.u64 	%rd3, %rd17;
	mov.u32 	%r17, %ctaid.x;
	mov.u32 	%r18, %ntid.x;
	mov.u32 	%r19, %tid.x;
	mad.lo.s32 	%r4, %r17, %r18, %r19;
	setp.ge.u32 	%p1, %r4, %r3;
	@%p1 bra 	$L__BB0_32;
	mov.u32 	%r5, %ctaid.y;
	setp.ge.u32 	%p2, %r5, %r2;
	@%p2 bra 	$L__BB0_32;
	cvt.u64.u32 	%rd4, %r5;
	cvta.to.global.u64 	%rd18, %rd14;
	mul.wide.u32 	%rd19, %r5, 8;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.nc.u32 	%r28, [%rd20];
	ld.global.nc.u32 	%r7, [%rd20+4];
	add.s32 	%r20, %r7, %r28;
	setp.ge.u32 	%p3, %r28, %r20;
	mov.f32 	%f108, 0f00000000;
	mov.f32 	%f107, %f108;
	@%p3 bra 	$L__BB0_31;
	cvt.u64.u32 	%rd5, %r1;
	add.s32 	%r21, %r4, %r4;
	cvt.u64.u32 	%rd6, %r21;
	mul.wide.u32 	%rd7, %r3, 2;
	cvt.u64.u32 	%rd8, %r2;
	add.s32 	%r22, %r7, -1;
	setp.lt.u32 	%p4, %r22, 3;
	mov.f32 	%f107, 0f00000000;
	mov.f32 	%f108, %f107;
	@%p4 bra 	$L__BB0_18;
	and.b32  	%r23, %r7, -4;
	neg.s32 	%r26, %r23;
	mul.wide.u32 	%rd21, %r28, 4;
	add.s64 	%rd22, %rd21, %rd3;
	add.s64 	%rd133, %rd22, 8;
	mov.f32 	%f107, 0f00000000;
$L__BB0_5:
	.pragma "nounroll";
	setp.ne.s32 	%p5, %r4, 0;
	ld.global.nc.u16 	%rs1, [%rd133+-8];
	cvt.u64.u16 	%rd23, %rs1;
	ld.global.nc.u16 	%rs2, [%rd133+-6];
	cvt.u64.u16 	%rd24, %rs2;
	mul.lo.s64 	%rd25, %rd23, %rd5;
	add.s64 	%rd26, %rd25, %rd24;
	mul.lo.s64 	%rd27, %rd7, %rd26;
	add.s64 	%rd28, %rd27, %rd6;
	shl.b64 	%rd29, %rd28, 2;
	add.s64 	%rd30, %rd2, %rd29;
	ld.global.nc.f32 	%f3, [%rd30];
	ld.global.nc.f32 	%f4, [%rd30+4];
	mul.lo.s64 	%rd31, %rd26, %rd8;
	add.s64 	%rd32, %rd31, %rd4;
	mul.lo.s64 	%rd33, %rd7, %rd32;
	add.s64 	%rd34, %rd33, %rd6;
	shl.b64 	%rd35, %rd34, 2;
	add.s64 	%rd36, %rd1, %rd35;
	ld.global.nc.f32 	%f5, [%rd36];
	ld.global.nc.f32 	%f6, [%rd36+4];
	@%p5 bra 	$L__BB0_7;
	fma.rn.f32 	%f109, %f3, %f5, %f108;
	fma.rn.f32 	%f110, %f4, %f6, %f107;
	bra.uni 	$L__BB0_8;
$L__BB0_7:
	fma.rn.f32 	%f85, %f3, %f5, %f108;
	neg.f32 	%f86, %f4;
	fma.rn.f32 	%f109, %f86, %f6, %f85;
	fma.rn.f32 	%f87, %f3, %f6, %f107;
	fma.rn.f32 	%f110, %f4, %f5, %f87;
$L__BB0_8:
	setp.eq.s32 	%p6, %r4, 0;
	ld.global.nc.u16 	%rs3, [%rd133+-4];
	cvt.u64.u16 	%rd37, %rs3;
	ld.global.nc.u16 	%rs4, [%rd133+-2];
	cvt.u64.u16 	%rd38, %rs4;
	mul.lo.s64 	%rd39, %rd37, %rd5;
	add.s64 	%rd40, %rd39, %rd38;
	mul.lo.s64 	%rd41, %rd7, %rd40;
	add.s64 	%rd42, %rd41, %rd6;
	shl.b64 	%rd43, %rd42, 2;
	add.s64 	%rd44, %rd2, %rd43;
	ld.global.nc.f32 	%f13, [%rd44];
	ld.global.nc.f32 	%f14, [%rd44+4];
	mul.lo.s64 	%rd45, %rd40, %rd8;
	add.s64 	%rd46, %rd45, %rd4;
	mul.lo.s64 	%rd47, %rd7, %rd46;
	add.s64 	%rd48, %rd47, %rd6;
	shl.b64 	%rd49, %rd48, 2;
	add.s64 	%rd50, %rd1, %rd49;
	ld.global.nc.f32 	%f15, [%rd50];
	ld.global.nc.f32 	%f16, [%rd50+4];
	@%p6 bra 	$L__BB0_10;
	fma.rn.f32 	%f88, %f13, %f15, %f109;
	neg.f32 	%f89, %f14;
	fma.rn.f32 	%f111, %f89, %f16, %f88;
	fma.rn.f32 	%f90, %f13, %f16, %f110;
	fma.rn.f32 	%f112, %f14, %f15, %f90;
	bra.uni 	$L__BB0_11;
$L__BB0_10:
	fma.rn.f32 	%f111, %f13, %f15, %f109;
	fma.rn.f32 	%f112, %f14, %f16, %f110;
$L__BB0_11:
	ld.global.nc.u16 	%rs5, [%rd133];
	cvt.u64.u16 	%rd51, %rs5;
	ld.global.nc.u16 	%rs6, [%rd133+2];
	cvt.u64.u16 	%rd52, %rs6;
	mul.lo.s64 	%rd53, %rd51, %rd5;
	add.s64 	%rd54, %rd53, %rd52;
	mul.lo.s64 	%rd55, %rd7, %rd54;
	add.s64 	%rd56, %rd55, %rd6;
	shl.b64 	%rd57, %rd56, 2;
	add.s64 	%rd58, %rd2, %rd57;
	ld.global.nc.f32 	%f23, [%rd58];
	ld.global.nc.f32 	%f24, [%rd58+4];
	mul.lo.s64 	%rd59, %rd54, %rd8;
	add.s64 	%rd60, %rd59, %rd4;
	mul.lo.s64 	%rd61, %rd7, %rd60;
	add.s64 	%rd62, %rd61, %rd6;
	shl.b64 	%rd63, %rd62, 2;
	add.s64 	%rd64, %rd1, %rd63;
	ld.global.nc.f32 	%f25, [%rd64];
	ld.global.nc.f32 	%f26, [%rd64+4];
	@%p6 bra 	$L__BB0_13;
	fma.rn.f32 	%f91, %f23, %f25, %f111;
	neg.f32 	%f92, %f24;
	fma.rn.f32 	%f113, %f92, %f26, %f91;
	fma.rn.f32 	%f93, %f23, %f26, %f112;
	fma.rn.f32 	%f114, %f24, %f25, %f93;
	bra.uni 	$L__BB0_14;
$L__BB0_13:
	fma.rn.f32 	%f113, %f23, %f25, %f111;
	fma.rn.f32 	%f114, %f24, %f26, %f112;
$L__BB0_14:
	ld.global.nc.u16 	%rs7, [%rd133+4];
	cvt.u64.u16 	%rd65, %rs7;
	ld.global.nc.u16 	%rs8, [%rd133+6];
	cvt.u64.u16 	%rd66, %rs8;
	mul.lo.s64 	%rd67, %rd65, %rd5;
	add.s64 	%rd68, %rd67, %rd66;
	mul.lo.s64 	%rd69, %rd7, %rd68;
	add.s64 	%rd70, %rd69, %rd6;
	shl.b64 	%rd71, %rd70, 2;
	add.s64 	%rd72, %rd2, %rd71;
	ld.global.nc.f32 	%f33, [%rd72];
	ld.global.nc.f32 	%f34, [%rd72+4];
	mul.lo.s64 	%rd73, %rd68, %rd8;
	add.s64 	%rd74, %rd73, %rd4;
	mul.lo.s64 	%rd75, %rd7, %rd74;
	add.s64 	%rd76, %rd75, %rd6;
	shl.b64 	%rd77, %rd76, 2;
	add.s64 	%rd78, %rd1, %rd77;
	ld.global.nc.f32 	%f35, [%rd78];
	ld.global.nc.f32 	%f36, [%rd78+4];
	@%p6 bra 	$L__BB0_16;
	fma.rn.f32 	%f94, %f33, %f35, %f113;
	neg.f32 	%f95, %f34;
	fma.rn.f32 	%f108, %f95, %f36, %f94;
	fma.rn.f32 	%f96, %f33, %f36, %f114;
	fma.rn.f32 	%f107, %f34, %f35, %f96;
	bra.uni 	$L__BB0_17;
$L__BB0_16:
	fma.rn.f32 	%f108, %f33, %f35, %f113;
	fma.rn.f32 	%f107, %f34, %f36, %f114;
$L__BB0_17:
	add.s32 	%r28, %r28, 4;
	add.s32 	%r26, %r26, 4;
	add.s64 	%rd133, %rd133, 16;
	setp.ne.s32 	%p9, %r26, 0;
	@%p9 bra 	$L__BB0_5;
$L__BB0_18:
	and.b32  	%r14, %r7, 3;
	setp.eq.s32 	%p10, %r14, 0;
	@%p10 bra 	$L__BB0_31;
	setp.eq.s32 	%p11, %r14, 1;
	@%p11 bra 	$L__BB0_27;
	setp.eq.s32 	%p12, %r4, 0;
	mul.wide.u32 	%rd79, %r28, 4;
	add.s64 	%rd12, %rd3, %rd79;
	ld.global.nc.u16 	%rs9, [%rd12];
	cvt.u64.u16 	%rd80, %rs9;
	ld.global.nc.u16 	%rs10, [%rd12+2];
	cvt.u64.u16 	%rd81, %rs10;
	mul.lo.s64 	%rd82, %rd80, %rd5;
	add.s64 	%rd83, %rd82, %rd81;
	mul.lo.s64 	%rd84, %rd7, %rd83;
	add.s64 	%rd85, %rd84, %rd6;
	shl.b64 	%rd86, %rd85, 2;
	add.s64 	%rd87, %rd2, %rd86;
	ld.global.nc.f32 	%f47, [%rd87];
	ld.global.nc.f32 	%f48, [%rd87+4];
	mul.lo.s64 	%rd88, %rd83, %rd8;
	add.s64 	%rd89, %rd88, %rd4;
	mul.lo.s64 	%rd90, %rd7, %rd89;
	add.s64 	%rd91, %rd90, %rd6;
	shl.b64 	%rd92, %rd91, 2;
	add.s64 	%rd93, %rd1, %rd92;
	ld.global.nc.f32 	%f49, [%rd93];
	ld.global.nc.f32 	%f50, [%rd93+4];
	@%p12 bra 	$L__BB0_22;
	fma.rn.f32 	%f98, %f47, %f49, %f108;
	neg.f32 	%f99, %f48;
	fma.rn.f32 	%f121, %f99, %f50, %f98;
	fma.rn.f32 	%f100, %f47, %f50, %f107;
	fma.rn.f32 	%f122, %f48, %f49, %f100;
	bra.uni 	$L__BB0_23;
$L__BB0_22:
	fma.rn.f32 	%f121, %f47, %f49, %f108;
	fma.rn.f32 	%f122, %f48, %f50, %f107;
$L__BB0_23:
	ld.global.nc.u16 	%rs11, [%rd12+4];
	cvt.u64.u16 	%rd94, %rs11;
	ld.global.nc.u16 	%rs12, [%rd12+6];
	cvt.u64.u16 	%rd95, %rs12;
	mul.lo.s64 	%rd96, %rd94, %rd5;
	add.s64 	%rd97, %rd96, %rd95;
	mul.lo.s64 	%rd98, %rd7, %rd97;
	add.s64 	%rd99, %rd98, %rd6;
	shl.b64 	%rd100, %rd99, 2;
	add.s64 	%rd101, %rd2, %rd100;
	ld.global.nc.f32 	%f57, [%rd101];
	ld.global.nc.f32 	%f58, [%rd101+4];
	mul.lo.s64 	%rd102, %rd97, %rd8;
	add.s64 	%rd103, %rd102, %rd4;
	mul.lo.s64 	%rd104, %rd7, %rd103;
	add.s64 	%rd105, %rd104, %rd6;
	shl.b64 	%rd106, %rd105, 2;
	add.s64 	%rd107, %rd1, %rd106;
	ld.global.nc.f32 	%f59, [%rd107];
	ld.global.nc.f32 	%f60, [%rd107+4];
	@%p12 bra 	$L__BB0_25;
	fma.rn.f32 	%f101, %f57, %f59, %f121;
	neg.f32 	%f102, %f58;
	fma.rn.f32 	%f108, %f102, %f60, %f101;
	fma.rn.f32 	%f103, %f57, %f60, %f122;
	fma.rn.f32 	%f107, %f58, %f59, %f103;
	bra.uni 	$L__BB0_26;
$L__BB0_25:
	fma.rn.f32 	%f108, %f57, %f59, %f121;
	fma.rn.f32 	%f107, %f58, %f60, %f122;
$L__BB0_26:
	add.s32 	%r28, %r28, 2;
$L__BB0_27:
	and.b32  	%r24, %r7, 1;
	setp.eq.b32 	%p14, %r24, 1;
	not.pred 	%p15, %p14;
	@%p15 bra 	$L__BB0_31;
	setp.eq.s32 	%p16, %r4, 0;
	mul.wide.u32 	%rd108, %r28, 4;
	add.s64 	%rd109, %rd3, %rd108;
	ld.global.nc.u16 	%rs13, [%rd109];
	cvt.u64.u16 	%rd110, %rs13;
	ld.global.nc.u16 	%rs14, [%rd109+2];
	cvt.u64.u16 	%rd111, %rs14;
	mul.lo.s64 	%rd112, %rd110, %rd5;
	add.s64 	%rd113, %rd112, %rd111;
	mul.lo.s64 	%rd114, %rd7, %rd113;
	add.s64 	%rd115, %rd114, %rd6;
	shl.b64 	%rd116, %rd115, 2;
	add.s64 	%rd117, %rd2, %rd116;
	ld.global.nc.f32 	%f71, [%rd117];
	ld.global.nc.f32 	%f72, [%rd117+4];
	mul.lo.s64 	%rd118, %rd113, %rd8;
	add.s64 	%rd119, %rd118, %rd4;
	mul.lo.s64 	%rd120, %rd7, %rd119;
	add.s64 	%rd121, %rd120, %rd6;
	shl.b64 	%rd122, %rd121, 2;
	add.s64 	%rd123, %rd1, %rd122;
	ld.global.nc.f32 	%f73, [%rd123];
	ld.global.nc.f32 	%f74, [%rd123+4];
	@%p16 bra 	$L__BB0_30;
	fma.rn.f32 	%f104, %f71, %f73, %f108;
	neg.f32 	%f105, %f72;
	fma.rn.f32 	%f108, %f105, %f74, %f104;
	fma.rn.f32 	%f106, %f71, %f74, %f107;
	fma.rn.f32 	%f107, %f72, %f73, %f106;
	bra.uni 	$L__BB0_31;
$L__BB0_30:
	fma.rn.f32 	%f108, %f71, %f73, %f108;
	fma.rn.f32 	%f107, %f72, %f74, %f107;
$L__BB0_31:
	ld.param.u64 	%rd132, [fused_mimo_param_2];
	cvt.u64.u32 	%rd124, %r3;
	mul.lo.s64 	%rd125, %rd4, %rd124;
	add.s64 	%rd126, %rd125, %rd125;
	add.s32 	%r25, %r4, %r4;
	cvt.u64.u32 	%rd127, %r25;
	add.s64 	%rd128, %rd126, %rd127;
	cvta.to.global.u64 	%rd129, %rd132;
	shl.b64 	%rd130, %rd128, 2;
	add.s64 	%rd131, %rd129, %rd130;
	st.global.f32 	[%rd131], %f108;
	st.global.f32 	[%rd131+4], %f107;
$L__BB0_32:
	ret;

}
